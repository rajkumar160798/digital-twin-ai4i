{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8d84f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BiGRUWithAttention:\n\tMissing key(s) in state_dict: \"bigru.weight_ih_l0\", \"bigru.weight_hh_l0\", \"bigru.bias_ih_l0\", \"bigru.bias_hh_l0\", \"bigru.weight_ih_l0_reverse\", \"bigru.weight_hh_l0_reverse\", \"bigru.bias_ih_l0_reverse\", \"bigru.bias_hh_l0_reverse\", \"attn.weight\", \"attn.bias\". \n\tUnexpected key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\". \n\tsize mismatch for fc.weight: copying a param with shape torch.Size([5, 64]) from checkpoint, the shape in current model is torch.Size([5, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m     25\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m  \u001b[38;5;66;03m# Change this to match your model's training configuration\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBiGRUWithAttention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../models/gru_digital_twin.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msensor_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub_Projects/digital-twin-ai4i/twin_model/utils.py:15\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_class, path, *args)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_class, path, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BiGRUWithAttention:\n\tMissing key(s) in state_dict: \"bigru.weight_ih_l0\", \"bigru.weight_hh_l0\", \"bigru.bias_ih_l0\", \"bigru.bias_hh_l0\", \"bigru.weight_ih_l0_reverse\", \"bigru.weight_hh_l0_reverse\", \"bigru.bias_ih_l0_reverse\", \"bigru.bias_hh_l0_reverse\", \"attn.weight\", \"attn.bias\". \n\tUnexpected key(s) in state_dict: \"gru.weight_ih_l0\", \"gru.weight_hh_l0\", \"gru.bias_ih_l0\", \"gru.bias_hh_l0\". \n\tsize mismatch for fc.weight: copying a param with shape torch.Size([5, 64]) from checkpoint, the shape in current model is torch.Size([5, 128])."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Add the parent directory to sys.path so twin_model can be imported\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from twin_model.model import BiGRUWithAttention\n",
    "from twin_model.utils import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load processed data\n",
    "df = pd.read_csv(\"../data/processed/ai4i_cleaned.csv\")\n",
    "sensor_cols = ['Air temperature [K]', 'Process temperature [K]',\n",
    "               'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "\n",
    "df_healthy = df[df['Machine failure'] == 0].reset_index(drop=True)\n",
    "sequence = df_healthy[sensor_cols].iloc[300:320].values\n",
    "\n",
    "# Load model\n",
    "hidden_size = 64  # Change this to match your model's training configuration\n",
    "model = load_model(BiGRUWithAttention, \"../models/bigru_attention_twin.pth\", len(sensor_cols), hidden_size)\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    input_tensor = torch.tensor(sequence).unsqueeze(0).float()  # shape: [1, 20, 5]\n",
    "    pred = model(input_tensor)[0].numpy()  # shape: [20, 5]\n",
    "\n",
    "# Compute metrics\n",
    "for i, col in enumerate(sensor_cols):\n",
    "    rmse = mean_squared_error(sequence[:, i], pred[:, i], squared=False)\n",
    "    mae = mean_absolute_error(sequence[:, i], pred[:, i])\n",
    "    print(f\"{col}: RMSE = {rmse:.4f}, MAE = {mae:.4f}\")\n",
    "\n",
    "# Optional: plot one sensor\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(sequence[:, 3], label=\"True Torque\")\n",
    "plt.plot(pred[:, 3], label=\"Predicted Torque\", linestyle='--')\n",
    "plt.title(\"Torque Prediction vs Ground Truth\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
